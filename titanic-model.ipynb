{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python libraries\n",
    "\n",
    "import pandas as pd  # data tools\n",
    "import numpy as np  # maths\n",
    "import seaborn as sns # visualizations\n",
    "# import missingno as msno # for NaN visualization\n",
    "import matplotlib.pyplot as plt # for data visualization, graph plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sweetviz as viz\n",
    "#from random import randint\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "#from scipy.stats import uniform\n",
    "#import sweetviz as viz\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 10)\n"
     ]
    }
   ],
   "source": [
    "# define the data set variables and their locations.\n",
    "\n",
    "data_folder = './data/titanic.csv'\n",
    "\n",
    "data = pd.read_csv(data_folder)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['survived'], axis=1)  # create the features 'x' dataset\n",
    "target = data['survived']  # create the target 'y' dataset\n",
    "features = pd.get_dummies(features) # create the feature columns for all of the feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>companions</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Cherbourg</th>\n",
       "      <th>embarked_Queenstown</th>\n",
       "      <th>embarked_Southampton</th>\n",
       "      <th>...</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>age cohort_adult</th>\n",
       "      <th>age cohort_child</th>\n",
       "      <th>age cohort_senior</th>\n",
       "      <th>age cohort_teenager</th>\n",
       "      <th>age cohort_toddler</th>\n",
       "      <th>age cohort_young adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pclass  sibsp  parch  companions  sex_female  sex_male  \\\n",
       "0           0       1      0      0           0           1         0   \n",
       "1           1       1      1      2           3           0         1   \n",
       "2           2       1      1      2           3           1         0   \n",
       "3           3       1      1      2           3           0         1   \n",
       "4           4       1      1      2           3           1         0   \n",
       "\n",
       "   embarked_Cherbourg  embarked_Queenstown  embarked_Southampton  ...  deck_E  \\\n",
       "0                   0                    0                     1  ...       0   \n",
       "1                   0                    0                     1  ...       0   \n",
       "2                   0                    0                     1  ...       0   \n",
       "3                   0                    0                     1  ...       0   \n",
       "4                   0                    0                     1  ...       0   \n",
       "\n",
       "   deck_F  deck_G  deck_T  age cohort_adult  age cohort_child  \\\n",
       "0       0       0       0                 0                 0   \n",
       "1       0       0       0                 0                 0   \n",
       "2       0       0       0                 0                 0   \n",
       "3       0       0       0                 0                 0   \n",
       "4       0       0       0                 0                 0   \n",
       "\n",
       "   age cohort_senior  age cohort_teenager  age cohort_toddler  \\\n",
       "0                  0                    0                   0   \n",
       "1                  0                    0                   1   \n",
       "2                  0                    0                   1   \n",
       "3                  0                    0                   0   \n",
       "4                  0                    1                   0   \n",
       "\n",
       "   age cohort_young adult  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features train and test:  (1047, 24) (262, 24)\n",
      "targets train and test:  (1047,) (262,)\n"
     ]
    }
   ],
   "source": [
    "# split up the data into test and training datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2, random_state=15)\n",
    "print(\"features train and test: \", X_train.shape, X_test.shape)\n",
    "print('targets train and test: ', y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done! Use 'show' commands to display/save.   |██████████| [100%]   00:01 -> (00:00 left)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report rpt_train.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# create an HTML report on the data\n",
    "report = viz.compare([X_train,\"train\"], [X_test, \"test\"],)\n",
    "report.show_html(\"rpt_train.html\") # Not providing a filename will default to SWEETVIZ_REPORT.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.815513</td>\n",
       "      <td>0.043893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.806896</td>\n",
       "      <td>0.045217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.801181</td>\n",
       "      <td>0.043467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.797335</td>\n",
       "      <td>0.048807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.790760</td>\n",
       "      <td>0.030253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.765925</td>\n",
       "      <td>0.027716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.762060</td>\n",
       "      <td>0.037454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.752555</td>\n",
       "      <td>0.026469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.737262</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy       Std\n",
       "Model Name                       \n",
       "GradientBoost  0.815513  0.043893\n",
       "SVC            0.806896  0.045217\n",
       "LogReg         0.801181  0.043467\n",
       "AdaBoost       0.797335  0.048807\n",
       "XGBoost        0.790760  0.030253\n",
       "RandomForest   0.765925  0.027716\n",
       "KNN            0.762060  0.037454\n",
       "ExtraTrees     0.752555  0.026469\n",
       "DecisionTree   0.737262  0.023654"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  cross validation using several classifiers\n",
    "\n",
    "random_state=15\n",
    "\n",
    "# Scale features such that the mean is 0 and standard deviation is 1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # calculate the mean and variance of each of the features\n",
    "X_test = scaler.transform(X_test) # transform each feature using the learned mean and variance\n",
    "\n",
    "# Number of cross-validation folds\n",
    "k_folds = 10\n",
    "\n",
    "# Number of estimators for tree-based ensembles\n",
    "n_estimators = 100\n",
    "\n",
    "# Create a dictionary containing the instance of the models, scores, mean accuracy and standard deviation\n",
    "classifiers = {\n",
    "    'name': ['DecisionTree', 'RandomForest', 'ExtraTrees', 'AdaBoost', 'LogReg', 'KNN', 'SVC',\n",
    "             'XGBoost', 'GradientBoost'],\n",
    "    'models': [DecisionTreeClassifier(random_state=random_state),\n",
    "               RandomForestClassifier(random_state=random_state, n_estimators=n_estimators),\n",
    "               ExtraTreesClassifier(random_state=random_state, n_estimators=n_estimators),\n",
    "               AdaBoostClassifier(random_state=random_state, n_estimators=n_estimators),\n",
    "               LogisticRegression(random_state=random_state),\n",
    "               KNeighborsClassifier(),\n",
    "               SVC(random_state=random_state),\n",
    "               XGBClassifier(random_state=random_state, n_estimators=n_estimators),\n",
    "               GradientBoostingClassifier(random_state=random_state, n_estimators=n_estimators)], \n",
    "    'scores': [],\n",
    "    'acc_mean': [],\n",
    "    'acc_std': []\n",
    "}\n",
    "\n",
    "# Run cross-validation and store the scores\n",
    "for model in classifiers['models']:\n",
    "    score = cross_val_score(model, X_train, y_train, cv=k_folds, n_jobs=4)\n",
    "    classifiers['scores'].append(score)\n",
    "    classifiers['acc_mean'].append(score.mean())\n",
    "    classifiers['acc_std'].append(score.std())    \n",
    "\n",
    "# send the results to a table\n",
    "classifiers_df = pd.DataFrame({\n",
    "    'Model Name': classifiers['name'],\n",
    "    'Accuracy': classifiers['acc_mean'],\n",
    "    'Std': classifiers['acc_std']\n",
    "}, columns=['Model Name', 'Accuracy', 'Std']).set_index('Model Name')\n",
    "\n",
    "classifiers_df.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we will be tuning the top three models\n",
    "1) GradientBoost \n",
    "2) SVC (support vector machine)\n",
    "3) LogReg (logistical regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for grid search - remove\n",
    "#gbc = GradientBoostingClassifier()\n",
    "\n",
    "# parameters = {\n",
    "#     \"n_estimators\":[5,50,250,500],\n",
    "#     \"max_depth\":[1,3,5,7,9],\n",
    "#     \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "# }\n",
    "#cv = GridSearchCV(gbc,parameters,cv=5)\n",
    "\n",
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"max_depth\":[3,5,8],\n",
    "#     \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "#     \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "#     \"n_estimators\":[10]\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for grid search - remove\n",
    "\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10, n_jobs=-1)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(clf.score(X_train, y_train))\n",
    "# print(clf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning the boost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "parameters_gbc = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": sp_randFloat(),\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\": sp_randInt(4, 10),\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\": sp_randFloat(),\n",
    "    \"n_estimators\": sp_randInt(100, 1000)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7946513849092646\n",
      "{'criterion': 'mae', 'learning_rate': 0.3817283830887682, 'loss': 'deviance', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 0.17272727272727273, 'min_samples_split': 0.2090909090909091, 'n_estimators': 194, 'subsample': 0.6376445486152407}\n"
     ]
    }
   ],
   "source": [
    "rand_cv= RandomizedSearchCV(GradientBoostingClassifier(), parameters_gbc, cv=2, n_jobs=-1)\n",
    "\n",
    "result = rand_cv.fit(X_train, y_train)\n",
    "print(rand_cv.score(X_train, y_train))\n",
    "print(rand_cv.best_params_)\n",
    "\n",
    "df_gridsearch = pd.DataFrame(result.cv_results_)\n",
    "df_gridsearch.insert(0,'model', 'GradientBoostingClassifier')\n",
    "\n",
    "best_estimator_boost = result.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.09923664122137%\n",
      "Confusion Matrix:\n",
      "[[144  23]\n",
      " [ 37  58]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_pred_y = best_estimator_boost.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(accuracy_score(y_test, best_pred_y)*100))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"{}\".format(confusion_matrix(y_test, best_pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "params_svm = {'C': [0.1, 1, 10, 50, 100, 1000],\n",
    "              'gamma': ['scale'],\n",
    "              'kernel':  ['poly', 'rbf', 'sigmoid']}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.804151 using {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_cv = GridSearchCV(SVC(), param_grid=params_svm, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "result = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "dftmp = pd.DataFrame(result.cv_results_)\n",
    "dftmp.insert(0,'model', 'svc')\n",
    "df_gridsearch = pd.concat([df_gridsearch, dftmp])\n",
    "\n",
    "best_estimator_svc = result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.62595419847328%\n",
      "Confusion Matrix:\n",
      "[[144  23]\n",
      " [ 33  62]]\n"
     ]
    }
   ],
   "source": [
    "best_pred_y = best_estimator_svc.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(accuracy_score(y_test, best_pred_y)*100))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"{}\".format(confusion_matrix(y_test, best_pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'penalty' : ['l2'],\n",
    "        'C' : [100, 10, 1.0, 0.1, 0.01]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.797839 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "              \n",
    "\n",
    "# define grid search\n",
    "# grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "rsf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params_lr, n_jobs=-1, cv=rsf, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "dftmp = pd.DataFrame(result.cv_results_)\n",
    "dftmp.insert(0,'model', 'svc')\n",
    "df_gridsearch = pd.concat([df_gridsearch, dftmp])\n",
    "\n",
    "best_estimator_lr = result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gridsearch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.62595419847328%\n",
      "Confusion Matrix:\n",
      "[[144  23]\n",
      " [ 33  62]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "best_pred_y = best_estimator_lr.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(accuracy_score(y_test, best_pred_y)*100))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"{}\".format(confusion_matrix(y_test, best_pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e36191fb3a17bab69645672dcaf6f0e65cba36cc4fd295c8c042128da1eed92"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
